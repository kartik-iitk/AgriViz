{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ca47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- Step 1: Load CSV files ---\n",
    "csv_files = glob.glob(\"../data/*.csv\")  # Adjust path or use absolute paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25025f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/hnn7hl3j01z6rnvld0st0lg40000gn/T/ipykernel_95133/470575609.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(file, on_bad_lines=\"warn\").drop(\n",
      "/var/folders/37/hnn7hl3j01z6rnvld0st0lg40000gn/T/ipykernel_95133/470575609.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(file, on_bad_lines=\"warn\").drop(\n",
      "/var/folders/37/hnn7hl3j01z6rnvld0st0lg40000gn/T/ipykernel_95133/470575609.py:3: ParserWarning: Skipping line 16251: expected 13 fields, saw 17\n",
      "\n",
      "  pd.read_csv(file, on_bad_lines=\"warn\").drop(\n"
     ]
    }
   ],
   "source": [
    "# Read and concatenate\n",
    "df_list = [\n",
    "    pd.read_csv(file, on_bad_lines=\"warn\").drop(\n",
    "        columns=[\"KccAns\", \"Year\", \"Month\", \"BlockName\"]\n",
    "    )\n",
    "    for file in csv_files\n",
    "]\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff10b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CreatedOn\"] = pd.to_datetime(df[\"CreatedOn\"], format=\"mixed\", errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d1afacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DistrictName\"] = df[\"DistrictName\"].astype(str)\n",
    "df[\"DistrictName\"] = df[\"DistrictName\"].str.strip()\n",
    "df[\"DistrictName\"] = df[\"DistrictName\"].replace(\"\", \"Unknown\")\n",
    "df[\"Season\"] = df[\"Season\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9d8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sector\"] = df[\"Sector\"].astype(str)\n",
    "df[\"Sector\"] = df[\"Sector\"].str.strip()  # Remove leading/trailing whitespace\n",
    "df[\"Sector\"] = df[\"Sector\"].replace(\n",
    "    [\"9999\", \"256\", \"825\"], \"Unknown\"\n",
    ")  # Replace empty strings with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc08a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Category\"] = df[\"Category\"].astype(str)\n",
    "df[\"Category\"] = df[\"Category\"].str.strip()  # Remove leading/trailing whitespace\n",
    "df[\"Category\"] = df[\"Category\"].replace(\n",
    "    [\"0\", 0, \"418\", \"417\", \"-1\", \"468\"], \"Unknown\"\n",
    ")  # Replace empty strings with 'Unknown'\n",
    "df[\"Category\"] = df[\"Category\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe9dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Crop\"] = df[\"Crop\"].astype(str)\n",
    "df[\"Crop\"] = df[\"Crop\"].fillna(\"Unknown\")\n",
    "df[\"Crop\"] = df[\"Crop\"].str.strip()  # Remove leading/trailing whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485c72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"QueryType\"] = df[\"QueryType\"].astype(str)\n",
    "df[\"QueryType\"] = df[\"QueryType\"].str.strip()  # Remove leading/trailing whitespace\n",
    "df[\"QueryType\"] = df[\"QueryType\"].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4055ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"QueryText\"] = df[\"QueryText\"].astype(str)\n",
    "df[\"QueryText\"] = df[\"QueryText\"].str.strip()  # Remove leading/trailing whitespace\n",
    "df[\"QueryText\"] = df[\"QueryText\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c2823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before compression:\n",
      "25291.230038642883 MB\n"
     ]
    }
   ],
   "source": [
    "# --- Step 2: Memory before optimization ---\n",
    "print(\"Memory usage before compression:\")\n",
    "print(df.memory_usage(deep=True).sum() / (1024**2), \"MB\")\n",
    "\n",
    "for col in df.select_dtypes(include=\"object\").columns:\n",
    "    num_unique = df[col].nunique()\n",
    "    num_total = len(df[col])\n",
    "    if num_unique / num_total < 0.02:  # Low cardinality\n",
    "        df[col] = df[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9f47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Save compressed DataFrame ---\n",
    "df.to_parquet(\"../data/compressed_df.parquet\", engine=\"pyarrow\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d296c865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after compression:\n",
      "5087.791198730469 MB\n",
      "Total size of CSV files on disk:\n",
      "15907.595109939575 MB\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Memory after optimization ---\n",
    "print(\"Memory usage after compression:\")\n",
    "print(df.memory_usage(deep=True).sum() / (1024**2), \"MB\")\n",
    "\n",
    "# --- Step 5: Get total size of the original CSVs ---\n",
    "total_csv_size = sum(os.path.getsize(file) for file in csv_files)\n",
    "print(\"Total size of CSV files on disk:\")\n",
    "print(total_csv_size / (1024**2), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6641876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines to read the parquet file\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.read_parquet('../data/compressed_df.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8ba73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
